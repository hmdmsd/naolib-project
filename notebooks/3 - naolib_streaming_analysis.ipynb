{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naolib Streaming Analysis\n",
    "\n",
    "This notebook performs streaming analysis on real-time Naolib transportation data using a simplified approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from kafka import KafkaConsumer\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('NaolibStreamingAnalysis') \\\n",
    "    .master('local[*]') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Function to Collect Data from Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Kafka configurations\n",
    "kafka_topic = \"naolib_realtime\"\n",
    "kafka_server = \"kafka:9092\"\n",
    "\n",
    "# Function to convert wait time text to minutes\n",
    "def convert_wait_time(wt):\n",
    "    if pd.isna(wt):\n",
    "        return None\n",
    "    if wt == \"proche\":\n",
    "        return 0\n",
    "    # Try to extract numbers\n",
    "    if isinstance(wt, str):\n",
    "        # If it's just a number\n",
    "        if wt.isdigit():\n",
    "            return int(wt)\n",
    "        # If it's in format \"XYmn\"\n",
    "        match = re.search(r'(\\d+)', wt)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Function to collect real-time data from Kafka\n",
    "def collect_realtime_data(max_messages=50, timeout=10):\n",
    "    \"\"\"\n",
    "    Collect real-time data from Kafka\n",
    "    max_messages: Maximum number of messages to collect\n",
    "    timeout: Time to wait for messages in seconds\n",
    "    \"\"\"\n",
    "    print(f\"Collecting up to {max_messages} messages from Kafka...\")\n",
    "    consumer = KafkaConsumer(\n",
    "        kafka_topic,\n",
    "        bootstrap_servers=kafka_server,\n",
    "        auto_offset_reset='earliest',\n",
    "        consumer_timeout_ms=timeout*1000\n",
    "    )\n",
    "    \n",
    "    messages = []\n",
    "    expanded_rows = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for message in consumer:\n",
    "        try:\n",
    "            msg_data = json.loads(message.value.decode('utf-8'))\n",
    "            messages.append(msg_data)\n",
    "            \n",
    "            # Extract data from the message\n",
    "            timestamp = msg_data.get('timestamp')\n",
    "            stop_code = msg_data.get('stop_code')\n",
    "            stop_name = msg_data.get('stop_name')\n",
    "            \n",
    "            # Process arrivals array\n",
    "            arrivals = msg_data.get('arrivals', [])\n",
    "            for arrival in arrivals:\n",
    "                new_row = {\n",
    "                    'timestamp': timestamp,\n",
    "                    'stop_code': stop_code,\n",
    "                    'stop_name': stop_name,\n",
    "                    'direction': arrival.get('sens'),\n",
    "                    'terminus': arrival.get('terminus'),\n",
    "                    'wait_time_text': arrival.get('temps'),\n",
    "                    'is_real_time': arrival.get('tempsReel'),\n",
    "                    'line_number': arrival.get('ligne', {}).get('numLigne'),\n",
    "                    'processing_time': pd.Timestamp.now()\n",
    "                }\n",
    "                expanded_rows.append(new_row)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message: {str(e)}\")\n",
    "        \n",
    "        if len(messages) >= max_messages:\n",
    "            break\n",
    "            \n",
    "        if time.time() - start_time > timeout:\n",
    "            break\n",
    "    \n",
    "    consumer.close()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if expanded_rows:\n",
    "        df = pd.DataFrame(expanded_rows)\n",
    "        df['wait_time_minutes'] = df['wait_time_text'].apply(convert_wait_time)\n",
    "        print(f\"Collected {len(messages)} messages with {len(expanded_rows)} arrivals\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"No data collected\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Streaming Analysis 1: Real-time Average Wait Times\n",
    "\n",
    "Our first streaming analysis calculates real-time average wait times with a 10-minute sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting up to 50 messages from Kafka...\n",
      "Collected 6 messages with 70 arrivals\n",
      "\n",
      "=== Real-time Average Wait Times by Line (10-minute window) ===\n",
      "Analysis time: 2025-03-25 00:07:31.723864\n",
      "No lines with enough data\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze real-time wait times\n",
    "def analyze_realtime_wait_times():\n",
    "    \"\"\"Analyze real-time wait times by line with a 10-minute window\"\"\"\n",
    "    \n",
    "    # Collect data\n",
    "    data = collect_realtime_data(max_messages=50, timeout=10)\n",
    "    if data.empty:\n",
    "        return\n",
    "    \n",
    "    # Group by line and calculate metrics\n",
    "    grouped = data.groupby('line_number').agg(\n",
    "        avg_wait_time=('wait_time_minutes', 'mean'),\n",
    "        std_wait_time=('wait_time_minutes', 'std'),\n",
    "        count=('wait_time_minutes', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Filter for lines with enough data\n",
    "    grouped = grouped[grouped['count'] >= 3]\n",
    "    \n",
    "    # Sort by average wait time\n",
    "    grouped = grouped.sort_values('avg_wait_time', ascending=False)\n",
    "    \n",
    "    # Print results\n",
    "    now = pd.Timestamp.now()\n",
    "    print(f\"\\n=== Real-time Average Wait Times by Line (10-minute window) ===\")\n",
    "    print(f\"Analysis time: {now}\")\n",
    "    \n",
    "    if not grouped.empty:\n",
    "        for _, row in grouped.iterrows():\n",
    "            print(f\"Line {row['line_number']}: {row['avg_wait_time']:.1f} minutes (Â±{row['std_wait_time']:.1f}) - {row['count']} observations\")\n",
    "    else:\n",
    "        print(\"No lines with enough data\")\n",
    "    \n",
    "    # Create visualization\n",
    "    if not grouped.empty:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='line_number', y='avg_wait_time', data=grouped)\n",
    "        plt.title(\"Real-time Average Wait Time by Line\")\n",
    "        plt.xlabel(\"Line Number\")\n",
    "        plt.ylabel(\"Average Wait Time (minutes)\")\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    return grouped\n",
    "\n",
    "# Run the analysis\n",
    "wait_times = analyze_realtime_wait_times()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Continuous Monitoring\n",
    "\n",
    "Let's run the analysis continuously to simulate streaming with sliding windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/3\n",
      "Collecting up to 50 messages from Kafka...\n",
      "Collected 6 messages with 70 arrivals\n",
      "\n",
      "=== Real-time Average Wait Times by Line (10-minute window) ===\n",
      "Analysis time: 2025-03-25 00:07:59.788239\n",
      "No lines with enough data\n",
      "\n",
      "Waiting 60 seconds for next analysis...\n",
      "\n",
      "Monitoring stopped by user.\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations to run\n",
    "num_iterations = 3\n",
    "interval_seconds = 60\n",
    "\n",
    "try:\n",
    "    for i in range(num_iterations):\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Iteration {i+1}/{num_iterations}\")\n",
    "        analyze_realtime_wait_times()\n",
    "        \n",
    "        if i < num_iterations - 1:\n",
    "            print(f\"\\nWaiting {interval_seconds} seconds for next analysis...\")\n",
    "            time.sleep(interval_seconds)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nMonitoring stopped by user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Streaming Analysis 2: Delay Detection\n",
    "\n",
    "Our second streaming analysis detects unusual delays using a 15-minute window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting up to 100 messages from Kafka...\n",
      "Collected 6 messages with 70 arrivals\n",
      "\n",
      "=== Real-time Delay Detection (15-minute window) ===\n",
      "Analysis time: 2025-03-25 00:08:23.674964\n",
      "Total delays detected: 0\n",
      "\n",
      "No significant delays detected.\n"
     ]
    }
   ],
   "source": [
    "# Define baseline wait time for delay detection\n",
    "typical_wait_time = 10  # minutes\n",
    "\n",
    "# Function to detect delays\n",
    "def detect_delays():\n",
    "    \"\"\"Detect unusual delays in real-time\"\"\"\n",
    "    \n",
    "    # Collect data\n",
    "    data = collect_realtime_data(max_messages=100, timeout=15)\n",
    "    if data.empty:\n",
    "        return\n",
    "    \n",
    "    # Mark delays - consider waits 50% above typical as delays\n",
    "    data['is_delayed'] = data['wait_time_minutes'] > (typical_wait_time * 1.5)\n",
    "    data['delay_minutes'] = data.apply(\n",
    "        lambda x: x['wait_time_minutes'] - typical_wait_time if x['is_delayed'] else 0, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Group by line and stop to detect patterns\n",
    "    grouped = data.groupby(['line_number', 'stop_name']).agg(\n",
    "        max_wait_time=('wait_time_minutes', 'max'),\n",
    "        avg_wait_time=('wait_time_minutes', 'mean'),\n",
    "        observation_count=('wait_time_minutes', 'count'),\n",
    "        delayed_count=('is_delayed', 'sum'),\n",
    "        avg_delay_minutes=('delay_minutes', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Filter for significant delays (at least 2 delayed observations)\n",
    "    significant = grouped[grouped['delayed_count'] >= 2]\n",
    "    \n",
    "    # Add severity classification\n",
    "    significant['delay_severity'] = 'MINOR'\n",
    "    significant.loc[significant['avg_delay_minutes'] > 10, 'delay_severity'] = 'MODERATE'\n",
    "    significant.loc[significant['avg_delay_minutes'] > 20, 'delay_severity'] = 'SEVERE'\n",
    "    \n",
    "    # Sort by severity\n",
    "    significant = significant.sort_values('avg_delay_minutes', ascending=False)\n",
    "    \n",
    "    # Print results\n",
    "    now = pd.Timestamp.now()\n",
    "    print(f\"\\n=== Real-time Delay Detection (15-minute window) ===\")\n",
    "    print(f\"Analysis time: {now}\")\n",
    "    print(f\"Total delays detected: {data['is_delayed'].sum()}\")\n",
    "    \n",
    "    if not significant.empty:\n",
    "        print(\"\\nSignificant Delays:\")\n",
    "        for _, row in significant.iterrows():\n",
    "            print(f\"DELAY ALERT: Line {row['line_number']} at {row['stop_name']} - {row['delay_severity']} delay of\"\n",
    "                  f\" {row['avg_delay_minutes']:.1f} minutes\")\n",
    "    else:\n",
    "        print(\"\\nNo significant delays detected.\")\n",
    "        \n",
    "    return significant\n",
    "\n",
    "# Run the delay detection\n",
    "delays = detect_delays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Continuous Delay Monitoring\n",
    "\n",
    "Let's monitor for delays continuously to simulate a real-time alert system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/3\n",
      "Collecting up to 100 messages from Kafka...\n",
      "Collected 6 messages with 70 arrivals\n",
      "\n",
      "=== Real-time Delay Detection (15-minute window) ===\n",
      "Analysis time: 2025-03-25 00:08:47.410507\n",
      "Total delays detected: 0\n",
      "\n",
      "No significant delays detected.\n",
      "\n",
      "Waiting 120 seconds for next detection...\n",
      "\n",
      "Monitoring stopped by user.\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations to run\n",
    "num_iterations = 3\n",
    "interval_seconds = 120\n",
    "\n",
    "try:\n",
    "    for i in range(num_iterations):\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Iteration {i+1}/{num_iterations}\")\n",
    "        detect_delays()\n",
    "        \n",
    "        if i < num_iterations - 1:\n",
    "            print(f\"\\nWaiting {interval_seconds} seconds for next detection...\")\n",
    "            time.sleep(interval_seconds)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nMonitoring stopped by user.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
